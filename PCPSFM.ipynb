{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCPSFM.ipynb","provenance":[{"file_id":"1XeJsX5dddJgwXtYYWqCVWc-7luQF3a5V","timestamp":1632465823267},{"file_id":"1sObOKi0eix1B1lg17_CDU71OXE5bL87G","timestamp":1624718019512},{"file_id":"19wB8rxE4RUdXtVQ2YqP2ib4Q3LcGScJ-","timestamp":1624542646198},{"file_id":"1o2h75LMxMD4Iq-q_PE9xqvvIgGeCCY4j","timestamp":1623829718821},{"file_id":"15u_bF_FdEKEeclYnh6Sv49JuVXP7O5Mc","timestamp":1622384338526},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1621845053670},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"4PIjPADW2cHx"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","general_path = \"/content/drive/My Drive/Colab Notebooks/\"\n","%cd /content/drive/My\\ Drive/Colab Notebooks/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WktkPXH3nfbU"},"source":["## Libaries"]},{"cell_type":"code","metadata":{"id":"nyBMeGXGna9h"},"source":["import os\n","import pickle\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gDwYK7IWNx5j"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"Cj6T2hEzNvuV"},"source":["from PIL import Image\n","\n","# Function that reshapes an array of size (m, n, z)\n","# to a vector of size (m * n * z, 1)\n","def image_to_vector(im, rgb=False):\n","  if rgb:\n","    length, height, depth = im.shape\n","    vec = im.reshape(length * height * depth, 1)\n","  else:\n","    length, height = im.shape\n","    vec = im.reshape(length * height, 1)\n","\n","  return vec \n","\n","# Function that reshapes a vector of size (m * n * z, 1)\n","# to an array of size (m, n, z)\n","def vector_to_image(vec, length, height, depth=1, rgb=False):\n","  if rgb:\n","    im = vec.reshape(length, height, depth)\n","  else:\n","    im = vec.reshape(length, height)\n","\n","  return im\n","\n","# Function that creates a matrix out of column vectors\n","def create_input_matrix(data_path, rgb=True):\n","  shape = None\n","  im_paths = []\n","\n","  for subdir, dirs, files in os.walk(data_path):\n","    for file in files:  \n","      file_path = subdir + '/' + file\n","      im = Image.open(file_path) # open aligned image\n","\n","      # do once for the first image\n","      if shape is None:\n","        shape = im.size\n","\n","        im_arr = np.asarray(im) # load image to array\n","        cp_arr = im_arr.copy()\n","        \n","        matrix = image_to_vector(cp_arr, rgb)\n","        im_paths.append(file_path)\n","        continue\n","\n","      assert im.size == shape\n","\n","      # repeat for the rest images in the set\n","      im_arr = np.asarray(im) # load image to array\n","      cp_arr = im_arr.copy()\n","      \n","      vec = image_to_vector(cp_arr, rgb)\n","      matrix = np.append(matrix, vec, axis=1)\n","      im_paths.append(file_path)\n","\n","  return matrix, im_paths\n","\n","# Function that creates a directory if it doesn't already exist\n","def create_dir(dir):\n","  if not os.path.exists(dir):\n","    os.makedirs(dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GfBGSjcHcsw"},"source":["## PCPSFM"]},{"cell_type":"code","metadata":{"id":"SviERX5nGMcB"},"source":["def soft_shrink(Χ, mu):\n","    \"\"\"\n","    Υ = sgn(Χ)max(|Χ| - mu, 0)\n","    \n","    Parameters\n","    ----------\n","    Χ: numpy array\n","    mu: thresholding parameter\n","    \n","    Returns:\n","    ----------\n","    Υ: numpy array\n","    \n","    \"\"\"\n","    Υ = np.maximum(Χ - mu, 0)\n","    Υ = Υ + np.minimum(Χ + mu, 0)\n","    \n","    return Υ\n","\n","def pcpsfm(X, W, S, U, V, alpha=np.nan, lamda=np.nan, beta=np.nan, mu=np.nan, tol=10**(-7), maxit=1000):\n","  \"\"\" \n","  Paper: Side Information for Face Completion: a Robust PCA Approach \n","  Authors: Niannan Xue, Jiankang Deng, Shiyang Cheng, Yannis Panagakis, Stefanos Zafeiriou\n","  Published in: IEEE Transactions on Pattern Analysis and Machine Intelligence (Volume: 41, Issue: 10, Oct. 1 2019)\n","\n","  Description\n","  ------------\n","  A Robust Principal Component Analysis implementation using side information with missing values and features incorporation (PCPSFM).\n","\n","  Parameters\n","  ----------\n","  X : observation (n1 x n2) matrix, which will be decomposed into a sparse matrix E and a low-rank matrix L.\n","\n","  W : mask / missing values (n1 x n2) matrix. \n","\n","  S : side information (n1 x n2) matrix.\n","\n","  U : feature (n1 x d1) matrix.\n","  \n","  V : feature (n2 x d2) matrix.\n","\n","  alpha: positive tuning parameter used in the calculation of B. \n","\n","  lamda : positive tuning parameter used in the calculation of E.\n","\n","  beta: scaling ratio factor (> 1), that helps mu reach an accelerated superlinear performance.\n","\n","  mu: postive tuning parameter used in augmented Lagrangian.\n","  \n","  tol : tolerance value for convergency.\n","\n","  maxit : maximum iteration.\n","  \n","  Returns\n","  ----------\n","  L : array-like, low-rank matrix.\n","\n","  E : array-like, sparse matrix.\n","\n","  niter : number of iteration.\n","  \"\"\" \n","\n","  # dimensions\n","  n1, n2 = X.shape\n","  \n","  d1 = U.shape[1]\n","  d2 = V.shape[1]\n","\n","  # B = H - D\n","  # H,D bilinear mappings \n","  H = np.zeros((d1,d2))\n","  B = np.zeros((d1,d2)) \n","\n","  # Lagrange multipliers\n","  Z = np.zeros((n1,n2)) \n","  N = np.zeros((d1,d2)) \n","\n","  # parameter setting\n","  if np.isnan(alpha):\n","    alpha = 10**(-1)\n","  if np.isnan(lamda):\n","    lamda = 1.0 / np.sqrt(max(n1,n2))\n","  if np.isnan(beta):\n","    beta = 1.0 / np.linalg.norm(X, 2) \n","  if np.isnan(mu):\n","    mu = 10**(-5)\n","  \n","  print(\"** Initial parameters **\")\n","  print('alpha {} lamda {} beta {} mu {}'.format(alpha, lamda, beta, mu))\n","\n","  # transpose feature matricies\n","  Ut = np.transpose(U)\n","  Vt = np.transpose(V)\n","\n","  for niter in range(maxit):\n","    print(\"Iteration \", niter)\n","   \n","    if (niter + 1) % 50 == 0: # every 50 iterations beta reduces by 0.05\n","      beta -= 0.05\n","      if beta <= 1.0: # if reaches 0 or less, assign beta its previous value\n","        beta = 1.05  # if beta <= 0.05, give it a fixed value (beta = 1.05)\n","\n","\n","    # E = Softshrinkage(λ/μ)(X - UHV* + (1/μ) Z) o W + (X - UHV* + (1/μ) Z) o (1 - W)\n","    R = X - np.dot(np.dot(U, H), Vt) + (1/mu) * Z     # R = X - UHV* + (1/μ) Z\n","    SS = soft_shrink(R, lamda/mu)                     # SS = Softshrinkage(λ/μ)(R)\n","    E = np.multiply(SS, W) + np.multiply(R, (1 - W))  # E = SS o W + R o (1 - W)\n","\n","\n","    # H = U* SVT(1/2μ)((1/2)(X - E + (1/μ)Z + U (B + U*SV - (1/μ)N) V*)) V\n","    P = 0.5 * (X - E + (1/mu) * Z + np.dot(np.dot(U, (B + np.dot(np.dot(Ut, S), V) - (1/mu) * N)), Vt)) # P = (1/2)(X - E + (1/μ)Z + U (B + U*SV - (1/μ)N) V*)\n","\n","    # SVT(1/2μ)(P)\n","    UH, sigmasH, VH = np.linalg.svd(P, full_matrices=False) \n","    sigmasH = soft_shrink(sigmasH, 1/(2*mu)) \n","    SigmaH = np.diag(sigmasH)\n","\n","    H = np.dot(np.dot(Ut, np.dot(np.dot(UH, SigmaH), VH)), V) # H = U* SVT(1/2μ)(P) V\n","\n","\n","    # B = SVT(a/μ) (H - U*SV + (1/μ)N)\n","    Q = H - np.dot(np.dot(Ut, S), V) + (1/mu) * N  # Q = (H - U*SV + (1/μ)N\n","    \n","    # SVT(a/μ)(Q)\n","    UB, sigmasB, VB = np.linalg.svd(Q, full_matrices=False)\n","    sigmasB = soft_shrink(sigmasB, alpha/mu) \n","    SigmaB = np.diag(sigmasB)\n","\n","    B = np.dot(np.dot(UB, SigmaB), VB)  # B = SVT(a/μ)(Q)\n","\n","\n","    # Z = Z + μ(X - E - UHV*)\n","    CoefZ = X - E - np.dot(np.dot(U, H), Vt) # CoefZ = X - E - UHV*\n","    Z = Z + mu * CoefZ; # Z = Z + μ * Coefz\n","\n","    # N = N + μ(H - B - U*SV)\n","    CoefN = H - B - np.dot(np.dot(Ut, S), V)  # CoefN = H - B - U*SV\n","    N = N + mu * CoefN; # N = N + μ * CoefN\n","\n","    # μ = μ x β\n","    mu = mu * beta          \n","\n","    print('beta {},  mu {}'.format(beta, mu))\n","\n","    cond1 = np.linalg.norm(CoefZ, 'fro') / np.linalg.norm(X, 'fro') # || X - E - UHV* ||F / ||X||F\n","    cond2 = np.linalg.norm(CoefN, 'fro') / np.linalg.norm(X, 'fro') # || H - B - U*SV ||F / ||X||F\n","    \n","    print('cond1 {} cond2 {} tol {}'.format(cond1, cond2, tol))\n","    print()\n","    \n","    # # save the currently calculated results to disk every 50 iterations\n","    # if (niter + 1) % 50 == 0:\n","    #   check_path = general_path + \"pcpsfm_checkpoint_\" + str(niter+1) + \".pkl\"\n","\n","    #   # Saving the objects:\n","    #   with open(check_path, 'wb') as f:  \n","    #     pickle.dump([np.dot(np.dot(U, H), Vt), E, niter], f)\n","\n","    if max(cond1, cond2) < tol: # if the maximum of the two conditions gets a value smaller than the tolerance, terminate the algorithm\n","      break\n","\n","  L = np.dot(np.dot(U, H), Vt)\n","\n","  return L, E, niter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wttrHCizQhxx"},"source":["# Classic RPCA"]},{"cell_type":"markdown","metadata":{"id":"wuqSyyQgkyaF"},"source":["### M Matrix"]},{"cell_type":"code","metadata":{"id":"oualbisuYkJ-"},"source":["# Create observation matrix\n","data_path = os.path.join(general_path, \"datasets/small/myceleba/\")\n","M, im_paths = create_input_matrix(data_path)\n","\n","# Store observation matrix \n","mat_path = os.path.join(general_path, \"myceleba_small_classic_matrix.pkl\")\n","with open(mat_path, 'wb') as f:  \n","  pickle.dump([M, im_paths], f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xucNRbC25WEt"},"source":["### Load Observation Matrix "]},{"cell_type":"code","metadata":{"id":"Iwe89aw26WVR"},"source":["mat_path = os.path.join(general_path, \"myceleba_small_classic_matrix.pkl\")\n","with open(mat_path, 'rb') as f:\n","  [M, im_paths] = pickle.load(f)\n","\n","M = M / 255 # normalize matrix\n","X = M"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VlNpc7lq7EaQ"},"source":["### Execution - lamda tuning"]},{"cell_type":"code","metadata":{"id":"XnaBZlib7EaV"},"source":["from PIL import Image, ImageOps\n","from pathlib import Path\n","\n","# Classic RPCA configuration\n","d1 = X.shape[0]\n","d2 = X.shape[1]\n","\n","U = np.identity(d1, np.float32)\n","V = np.identity(d2, np.float32)\n","S = np.zeros((d1, d2), np.float32)\n","W = np.full((d1, d2), 1, np.float32)\n","\n","res_path = os.path.join(general_path, \"results/\") # directory containing all the results\n","create_dir(res_path)\n","\n","# lamda values\n","lamda_list = [1.0 / np.sqrt(max(d1,d2)), 0.01, 0.1]\n","\n","lamda_path = os.path.join(general_path, \"results/myceleba_classic/\") # directory to store the results\n","create_dir(lamda_path)\n","\n","# Execute CRPCA for each lamda value\n","for lamda in lamda_list:\n","  L, E, niter = pcpsfm(X, W, S, U, V, alpha=0.0, lamda=lamda, beta=1.5, mu=10**(-5), tol=10**(-7))\n","  print(\"Converges at \", niter, \"iteratons\")\n","\n","  # Store CRPCA return values\n","  pkl_name =  \"myceleba_lam_\" + str(round(lamda, 4)) + \"_results.pkl\"\n","  results_path = os.path.join(lamda_path, pkl_name)\n","  with open(results_path, 'wb') as f:  \n","    pickle.dump([L, E, niter], f)\n","\n","  # Create directory to store the results\n","  res_name = \"lam_\" + str(round(lamda, 4)) + \"/\"\n","  res_dir = os.path.join(lamda_path, res_name)\n","  create_dir(res_dir)\n","  \n","  # Create directory to store only the inpainting results\n","  L_name = \"lam_\" + str(round(lamda, 4)) + \"_L/\"\n","  L_dir = os.path.join(lamda_path, L_name)\n","  create_dir(L_dir)\n","\n","  # List the occluded images\n","  occ_dir = os.path.join(general_path, \"myceleba_occlusions/\")\n","  occ_list = os.listdir(occ_dir)\n","\n","  # Locate occluded images \n","  for case in occ_list:\n","    case_paths = [path for path in im_paths if case in path]\n","    \n","    file_path = Path(case_paths[0])\n","    parent_path = file_path.parent.absolute()\n","    id_dir = os.path.basename(parent_path)\n","    id_path = os.path.join(res_dir, id_dir)\n","    create_dir(id_path)\n","    idL_path = os.path.join(L_dir, id_dir)\n","    create_dir(idL_path)\n","    \n","    # Get the index of occluded image in list of paths\n","    ind = im_paths.index(case_paths[0]) \n","    col = ind\n","\n","    # Create arrays from column vectors\n","    X_arr = vector_to_image(X[:, col], 102, 100, 3, True)\n","    L_arr = vector_to_image(L[:, col], 102, 100, 3, True)\n","    E_arr = vector_to_image(E[:, col], 102, 100, 3, True)\n","\n","    # Covert arrays to images\n","    imX = Image.fromarray((X_arr * 255).astype(np.uint8))\n","    imL = Image.fromarray((L_arr * 255).astype(np.uint8))\n","    imE = Image.fromarray((E_arr * 255).astype(np.uint8))\n","\n","    # Store initial, low-rank and sparse images\n","    file_name, file_extension = os.path.splitext(case)\n","\n","    X_name = file_name + '_X' + file_extension\n","    L_name = file_name + '_L' + file_extension\n","    E_name = file_name + '_E' + file_extension\n","\n","    X_path = os.path.join(id_path, X_name)\n","    L_path = os.path.join(id_path, L_name)\n","    LL_path = os.path.join(idL_path, L_name)\n","    E_path = os.path.join(id_path, E_name)\n","\n","    imX.save(X_path)\n","    imL.save(L_path)\n","    imL.save(LL_path)\n","    imE.save(E_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Go9ZAOVh0xfj"},"source":["# PCPF"]},{"cell_type":"markdown","metadata":{"id":"lXP_t3F9xyBN"},"source":["### Train Matrix"]},{"cell_type":"code","metadata":{"id":"aYDbNSD-xyBN"},"source":["# Create observation matrix\n","train_path = os.path.join(general_path, \"datasets/small/myceleba_split/train/\")\n","M, train_im_paths = create_input_matrix(train_path)\n","\n","# Store observation matrix \n","train_mat_path = os.path.join(general_path, \"myceleba_train_matrix.pkl\")\n","with open(train_mat_path, 'wb') as f:  \n","  pickle.dump([M, train_im_paths], f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ScQySQ1wxyBN"},"source":["### Test Matrix"]},{"cell_type":"code","metadata":{"id":"CAVHvoRIxyBN"},"source":["# Create observation matrix\n","test_path = os.path.join(general_path, \"datasets/small/myceleba_split/test/\")\n","X, test_im_paths = create_input_matrix(test_path)\n","\n","# Store observation matrix \n","test_mat_path = os.path.join(general_path, \"myceleba_small_test_matrix.pkl\")\n","with open(test_mat_path, 'wb') as f:  \n","  pickle.dump([X, test_im_paths], f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vszz5gv8xyBO"},"source":["### Load Train, Test Matrices "]},{"cell_type":"code","metadata":{"id":"R5Gv2OOFxyBO"},"source":["train_mat_path = os.path.join(general_path, \"myceleba_train_matrix.pkl\")\n","with open(train_mat_path, 'rb') as f:\n","  [M, train_im_paths] = pickle.load(f)\n","\n","M = M / 255 # normalize matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIyc-WdPxyBO"},"source":["test_mat_path = os.path.join(general_path, \"myceleba_small_test_matrix.pkl\")\n","\n","# Getting back the objects:\n","with open(test_mat_path, 'rb') as f:\n","  [X, test_im_paths] = pickle.load(f)\n","\n","X = X / 255 # normalize matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FxbLa63PxyBP"},"source":["### Create U Matrix"]},{"cell_type":"code","metadata":{"id":"9E2I99ylxyBP"},"source":["U, _, _ = np.linalg.svd(M, full_matrices=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bgBTgyez0xgA"},"source":["### Execution - lamda tuning"]},{"cell_type":"code","metadata":{"id":"k3z-OScf0xgB"},"source":["from PIL import Image, ImageOps\n","from pathlib import Path\n","\n","# PCPF configuration\n","d1 = X.shape[0]\n","d2 = X.shape[1]\n","\n","V = np.identity(d2, np.float32)\n","S = np.zeros((d1, d2), np.float32)\n","W = np.full((d1, d2), 1, np.float32)\n","\n","res_path = os.path.join(general_path, \"results/\") # directory containing all the results\n","create_dir(res_path)\n","\n","# lamda values\n","lamda_list = [1.0 / np.sqrt(max(d1,d2)), 0.01, 0.1]\n","\n","lamda_path = os.path.join(general_path, \"results/myceleba_pcpf/\") # directory to store the results\n","create_dir(lamda_path)\n","\n","# Execute CRPCA for each lamda value\n","for lamda in lamda_list:\n","  L, E, niter = pcpsfm(X, W, S, U, V, alpha=0.0, lamda=lamda, beta=1.2, mu=10**(-5), tol=10**(-7))\n","  print(\"Converges at \", niter, \"iteratons\")\n","\n","  # Store CRPCA return values\n","  pkl_name =  \"myceleba_lam_\" + str(round(lamda, 4)) + \"_results.pkl\"\n","  results_path = os.path.join(lamda_path, pkl_name)\n","  with open(results_path, 'wb') as f:  \n","    pickle.dump([L, E, niter], f)\n","\n","  # Create directory to store the results\n","  res_name = \"lam_\" + str(round(lamda, 4)) + \"/\"\n","  res_dir = os.path.join(lamda_path, res_name)\n","  create_dir(res_dir)\n","  \n","  # Create directory to store only the inpainting results\n","  L_name = \"lam_\" + str(round(lamda, 4)) + \"_L/\"\n","  L_dir = os.path.join(lamda_path, L_name)\n","  create_dir(L_dir)\n","\n","  # List the occluded images\n","  occ_dir = os.path.join(general_path, \"datasets/small/myceleba_occlusions/\")\n","  occ_list = os.listdir(occ_dir)\n","\n","  # Locate occluded images \n","  for case in occ_list:\n","    case_paths = [path for path in test_im_paths if case in path]\n","    \n","    file_path = Path(case_paths[0])\n","    parent_path = file_path.parent.absolute()\n","    id_dir = os.path.basename(parent_path)\n","    id_path = os.path.join(res_dir, id_dir)\n","    create_dir(id_path)\n","    idL_path = os.path.join(L_dir, id_dir)\n","    create_dir(idL_path)\n","\n","    # Get the index of occluded image in list of paths\n","    ind = test_im_paths.index(case_paths[0]) \n","    col = ind\n","\n","    # Create arrays from column vectors\n","    X_arr = vector_to_image(X[:, col], 102, 100, 3, True)\n","    L_arr = vector_to_image(L[:, col], 102, 100, 3, True)\n","    E_arr = vector_to_image(E[:, col], 102, 100, 3, True)\n","\n","    # Covert arrays to images\n","    imX = Image.fromarray((X_arr * 255).astype(np.uint8))\n","    imL = Image.fromarray((L_arr * 255).astype(np.uint8))\n","    imE = Image.fromarray((E_arr * 255).astype(np.uint8))\n","\n","    # Store initial, low-rank and sparse images\n","    file_name, file_extension = os.path.splitext(case)\n","\n","    X_name = file_name + '_X' + file_extension\n","    L_name = file_name + '_L' + file_extension\n","    E_name = file_name + '_E' + file_extension\n","\n","    X_path = os.path.join(id_path, X_name)\n","    L_path = os.path.join(id_path, L_name)\n","    LL_path = os.path.join(idL_path, L_name)\n","    E_path = os.path.join(id_path, E_name)\n","\n","    imX.save(X_path)\n","    imL.save(L_path)\n","    imL.save(LL_path)\n","    imE.save(E_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EM2xBtDr4Me0"},"source":["# PCPFM"]},{"cell_type":"markdown","metadata":{"id":"JJN9mGK04MfN"},"source":["### Train Matrix"]},{"cell_type":"code","metadata":{"id":"eXqk2Uzh4MfO"},"source":["# Create observation matrix\n","train_path = os.path.join(general_path, \"datasets/small/myceleba_split/train/\")\n","M, train_im_paths = create_input_matrix(train_path)\n","\n","# Store observation matrix \n","train_mat_path = os.path.join(general_path, \"myceleba_train_matrix.pkl\")\n","with open(train_mat_path, 'wb') as f:  \n","  pickle.dump([M, train_im_paths], f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bdfb7_Qe4MfO"},"source":["### Test Matrix"]},{"cell_type":"code","metadata":{"id":"mie_kGzy4MfO"},"source":["# Create observation matrix\n","test_path = os.path.join(general_path, \"datasets/small/myceleba_split/test/\")\n","X, test_im_paths = create_input_matrix(test_path)\n","\n","# Store observation matrix \n","test_mat_path = os.path.join(general_path, \"myceleba_small_test_matrix.pkl\")\n","with open(test_mat_path, 'wb') as f:  \n","  pickle.dump([X, test_im_paths], f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xIbLvFzM4MfP"},"source":["### Load Train, Test Matrices "]},{"cell_type":"code","metadata":{"id":"D4xBE5vY4MfP"},"source":["train_mat_path = os.path.join(general_path, \"myceleba_train_matrix.pkl\")\n","with open(train_mat_path, 'rb') as f:\n","  [M, train_im_paths] = pickle.load(f)\n","\n","M = M / 255 # normalize matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2JxxSo44MfP"},"source":["test_mat_path = os.path.join(general_path, \"myceleba_test_matrix.pkl\")\n","\n","# Getting back the objects:\n","with open(test_mat_path, 'rb') as f:\n","  [X, test_im_paths] = pickle.load(f)\n","\n","X = X / 255 # normalize matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cYJ_KJZq4MfP"},"source":["### Create U Matrix"]},{"cell_type":"code","metadata":{"id":"CSS1WW484MfQ"},"source":["U, _, _ = np.linalg.svd(M, full_matrices=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9sAWC0ZZ2kOD"},"source":["### Create W Matrix"]},{"cell_type":"code","metadata":{"id":"OoDbcsxG2O1X"},"source":["from PIL import Image, ImageOps\n","\n","# List the mask images\n","mask_dir = os.path.join(general_path, \"myceleba_masks/\")\n","mask_list = os.listdir(mask_dir)\n","\n","W_list = []\n","\n","# Traverse all the test set masks\n","for i, case in enumerate(test_im_paths):\n","  file_name = os.path.basename(case)\n","  if file_name in mask_list:  # Find mask that corresponds to an occluded image\n","    mask_path = os.path.join(mask_dir, file_name)\n","    mask = Image.open(mask_path)\n","    mask = ImageOps.invert(mask) # Invert mask colors\n","    mask_arr = np.asarray(mask) # Convert mask image to array\n","\n","    # Create column vector with mask pixels\n","    Wi = mask_arr / 255\n","    Wi_rgb = np.dstack((Wi, Wi, Wi))\n","    W_vec = image_to_vector(Wi_rgb, True)\n","    W_list.append(W_vec.tolist())\n","\n","  else: # Fill column vectors with 1 for non-occluded images\n","    W_vec = np.full((X.shape[0], 1), 1.0, np.float64)\n","    W_list.append(W_vec.tolist())\n","\n","W = np.array(W_list)\n","W = np.squeeze(W, 2)\n","W = np.transpose(W, (1, 0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sn3DWPW4MfQ"},"source":["### Execution - lamda tuning"]},{"cell_type":"code","metadata":{"id":"FjVNelLW4MfQ"},"source":["from PIL import Image, ImageOps\n","from pathlib import Path\n","\n","# Classic RPCA configuration\n","d1 = X.shape[0]\n","d2 = X.shape[1]\n","\n","V = np.identity(d2, np.float32)\n","S = np.zeros((d1, d2), np.float32)\n","\n","res_path = os.path.join(general_path, \"results/\") # directory containing all the results\n","create_dir(res_path)\n","\n","# lamda values\n","lamda_list = [1.0 / np.sqrt(max(d1,d2)), 0.01, 0.1]\n","\n","lamda_path = os.path.join(general_path, \"results/myceleba_pcpfm/\") # directory to store the results\n","create_dir(lamda_path)\n","\n","# Execute CRPCA for each lamda value\n","for lamda in lamda_list:\n","  L, E, niter = pcpsfm(X, W, S, U, V, alpha=0.0, lamda=lamda, beta=1.2, mu=10**(-5), tol=10**(-7))\n","  print(\"Converges at \", niter, \"iteratons\")\n","\n","  # Store CRPCA return values\n","  pkl_name =  \"myceleba_lam_\" + str(round(lamda, 4)) + \"_results.pkl\"\n","  results_path = os.path.join(lamda_path, pkl_name)\n","  with open(results_path, 'wb') as f:  \n","    pickle.dump([L, E, niter], f)\n","\n","  # Create directory to store the results\n","  res_name = \"lam_\" + str(round(lamda, 4)) + \"/\"\n","  res_dir = os.path.join(lamda_path, res_name)\n","  create_dir(res_dir)\n","  \n","  # Create directory to store only the inpainting results\n","  L_name = \"lam_\" + str(round(lamda, 4)) + \"_L/\"\n","  L_dir = os.path.join(lamda_path, L_name)\n","  create_dir(L_dir)\n","\n","  # List the occluded images\n","  occ_dir = os.path.join(general_path, \"myceleba_occlusions/\")\n","  occ_list = os.listdir(occ_dir)\n","\n","  # Locate occluded images \n","  for case in occ_list:\n","    case_paths = [path for path in test_im_paths if case in path]\n","    \n","    file_path = Path(case_paths[0])\n","    parent_path = file_path.parent.absolute()\n","    id_dir = os.path.basename(parent_path)\n","    id_path = os.path.join(res_dir, id_dir)\n","    create_dir(id_path)\n","    idL_path = os.path.join(L_dir, id_dir)\n","    create_dir(idL_path)\n","\n","    # Get the index of occluded image in list of paths\n","    ind = test_im_paths.index(case_paths[0]) \n","    col = ind\n","\n","    # Create arrays from column vectors\n","    X_arr = vector_to_image(X[:, col], 102, 100, 3, True)\n","    L_arr = vector_to_image(L[:, col], 102, 100, 3, True)\n","    E_arr = vector_to_image(E[:, col], 102, 100, 3, True)\n","\n","    # Covert arrays to images\n","    imX = Image.fromarray((X_arr * 255).astype(np.uint8))\n","    imL = Image.fromarray((L_arr * 255).astype(np.uint8))\n","    imE = Image.fromarray((E_arr * 255).astype(np.uint8))\n","\n","    # Store initial, low-rank and sparse images\n","    file_name, file_extension = os.path.splitext(case)\n","\n","    X_name = file_name + '_X' + file_extension\n","    L_name = file_name + '_L' + file_extension\n","    E_name = file_name + '_E' + file_extension\n","\n","    X_path = os.path.join(id_path, X_name)\n","    L_path = os.path.join(id_path, L_name)\n","    LL_path = os.path.join(idL_path, L_name)\n","    E_path = os.path.join(id_path, E_name)\n","\n","    imX.save(X_path)\n","    imL.save(L_path)\n","    imL.save(LL_path)\n","    imE.save(E_path)"],"execution_count":null,"outputs":[]}]}